{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alien-filling",
   "metadata": {},
   "source": [
    "# This script identifies and deletes point features that have an identical attribute (settlement name) within a predefined distance of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "native-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from math import radians, sin, cos, acos\n",
    "import arcpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-trick",
   "metadata": {},
   "source": [
    "# Read data and define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patient-syracuse",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#df = gpd.read_file(r'C:\\Users\\Kelly\\Documents\\GIS_COLUMBIA\\SSD\\SSD_Settlements\\SharedWithPartners\\SSD_StlPnt_V01_alpha\\SSD_StlPnt_V01_alpha.shp')\n",
    "dataDir = r'C:\\Users\\Kelly\\Documents\\ArcGIS\\Projects\\ssdSttl\\ssdSttl.gdb'\n",
    "df = gpd.read_file(dataDir, driver = 'FileGDB', layer = 'grid_reach_layer1_2_3_all')\n",
    "\n",
    "data_path = r'C:\\Users\\Kelly\\Documents\\GIS_COLUMBIA\\SSD\\SSD_Settlements'\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-essex",
   "metadata": {},
   "source": [
    "# The column names used in the script are:\n",
    "longitude cloumn = x; latitude column = y\n",
    "\n",
    "\n",
    "The column that contains possible duplicate attributes is \"name\".\n",
    "\n",
    "Insert the field names, which are in your input shapefile, as dataframe column names below on the right side under #define your variables.\n",
    "\n",
    "The variables to the left are those used by the script. Do not change those.\n",
    "\n",
    "Define the threshold distance (meter). The script will search for duplicate names within this distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dense-fleece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30677, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define your variables on the right\n",
    "df['x'] = df['long']    #longitude values of the point locations\n",
    "df['y']  = df['lat']    #latitude vaues of the point locations\n",
    "df['name'] = df['name'] #place names of the locations\n",
    "\n",
    "#Define the threshold distance (meter). The script will search for duplicate names within this distance.\n",
    "threshold = 500\n",
    "\n",
    "#Explore your data. Print row- and column counts.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-symphony",
   "metadata": {},
   "source": [
    "# Define function that will calculate distances between points in meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "related-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    # convert degrees to radians\n",
    "    lon1 = np.deg2rad(lon1)\n",
    "    lat1 = np.deg2rad(lat1)\n",
    "    lon2 = np.deg2rad(lon2)\n",
    "    lat2 = np.deg2rad(lat2)\n",
    "\n",
    "    # formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r_e = 6371\n",
    "    return c * r_e*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-study",
   "metadata": {},
   "source": [
    "# Run function and calculate distances between points with identical name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exclusive-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add index column as reference for future query and join\n",
    "df['index_col'] = df.index\n",
    "\n",
    "#Code merge\n",
    "# merge dataframe on settlement names\n",
    "m = df.reset_index().merge(df.reset_index(), on='name')\n",
    "\n",
    "# Calculate Distance\n",
    "m['distance'] = haversine(m.x_x, m.y_x, m.x_y, m.y_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-throat",
   "metadata": {},
   "source": [
    "# Calculate midpoint coordinates and create unique identifier of the midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exclusive-component",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "m['Xmid']= (m['x_y']+m['x_x'])/2\n",
    "m['Ymid']= (m['y_y']+m['y_x'])/2\n",
    "\n",
    "#concatenate midpoint x,y values to create unique identifiers\n",
    "m['MID'] = m['Xmid'].astype(str) + m['Ymid'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-instrument",
   "metadata": {},
   "source": [
    "# Select distances less or equal threshold distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excited-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.drop(m[m.distance == 0].index, inplace=True)\n",
    "\n",
    "#specify threshold distance. Beyond this distance all duplicate names will be deleted.\n",
    "m.drop(m[m.distance > threshold].index, inplace=True) \n",
    "\n",
    "#print(m.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-minority",
   "metadata": {},
   "source": [
    "# Save duplicate locations that sould be deleted as shapefile, if you would like to explore those later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "periodic-motivation",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index_x      name    lat_x     long_x    distance  \\\n",
      "13        3  LOMIYEGA  4.57257  31.958799  315.162902   \n",
      "17     5122  LOMIYEGA  4.57000  31.959999  315.162902   \n",
      "76    19405    MURGAN  8.06795  27.857599  372.469294   \n",
      "82    29668    MURGAN  8.06997  27.854900  372.469294   \n",
      "85    29668    MURGAN  8.06997  27.854900  414.333243   \n",
      "\n",
      "                             MID  index_col_x                  geometry  \n",
      "13  31.959399219954.571285009845            3  POINT (31.95880 4.57257)  \n",
      "17  31.959399219954.571285009845         5122  POINT (31.96000 4.57000)  \n",
      "76     27.856249818.068960189715        19405  POINT (27.85760 8.06795)  \n",
      "82     27.856249818.068960189715        29668  POINT (27.85490 8.06997)  \n",
      "85   27.85305022998.069630145965        29668  POINT (27.85490 8.06997)  \n"
     ]
    }
   ],
   "source": [
    "df1 = m[['index_x', 'name', 'lat_x','long_x','distance','MID', 'index_col_x']].copy()\n",
    "gdf = gpd.GeoDataFrame(df1, geometry=gpd.points_from_xy(df1.long_x, df1.lat_x))\n",
    "gdf.to_file(os.path.join(data_path, \"ssd_dupl_to_delete.shp\"))\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-federal",
   "metadata": {},
   "source": [
    "# Delete duplicated name locations within threshold distance and save cleaned layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "productive-antibody",
   "metadata": {
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1.sort_values(['name', 'MID'], ascending = True)\n",
    "df3 = df2.drop_duplicates(subset='MID', keep=\"first\")\n",
    "\n",
    "df4 = df3.sort_values(['index_col_x'], ascending = True)\n",
    "df5 = df4.drop_duplicates(subset='index_col_x', keep=\"first\")\n",
    "df5.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suitable-polish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30677, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm = pd.merge(left=df, right=df5, how = 'left', left_on ='index_col',right_on='index_col_x')\n",
    "dfm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "early-deficit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29961, 31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.rename(columns={'name_x':'name'}, inplace = True)\n",
    "df_select = dfm.loc[dfm['MID'].isnull()]\n",
    "df_select.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "powered-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df_select.iloc[:, :19]\n",
    "gdf = gpd.GeoDataFrame(df3, geometry=gpd.points_from_xy(df3.long, df3.lat))\n",
    "gdf.to_file(os.path.join(data_path, \"ssd_dupl_500m_deleted.shp\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
